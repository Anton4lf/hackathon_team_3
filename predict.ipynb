{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as sns\n",
    "# import pandas as np\n",
    "# import seaborn as pd\n",
    "# import matplotlib.pyplot as torch\n",
    "# import catboost as plt\n",
    "\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor, VotingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, LearningCurveDisplay, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from torch.nn import functional as F\n",
    " \n",
    "device = torch.device('cpu')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(df: pd.DataFrame or None=None, choosen_model='ExtraTreesRegressor', show_features=False): # or CatBoostRegressor or VotingRegressor\n",
    "    '''\n",
    "    Automatically make prediction, including encoding and everythin\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    df: DataFrame\n",
    "        Dataset to prediction must contains same features\n",
    "        (use show_features)\n",
    "    choosen_model: str default=\"ExtraTreesRegressor\"\n",
    "        Use model from fitted_models.pkl, available models:\n",
    "        ExtraTreesRegressor, CatBoostRegressor, VotingRegressor \n",
    "    show_features: bool default=False\n",
    "        Print necessary features\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    predicted_values\n",
    "    '''\n",
    "\n",
    "    fitted_models = pickle.load(open('fitted_models.pkl', 'rb'))\n",
    "    features = fitted_models['features']\n",
    "\n",
    "    if show_features:\n",
    "        print(features)\n",
    "        return\n",
    "    \n",
    "    model = fitted_models[choosen_model]\n",
    "    \n",
    "    df_codes = deepcopy(df[features])\n",
    "\n",
    "    for col in df[features]:\n",
    "        if df[col].dtype == object:\n",
    "            df_codes[col] = pd.Categorical(df[col])\n",
    "            df_codes[col] = df_codes[col].cat.codes\n",
    "            \n",
    "    return model.predict(df_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция, кодирующая категориальные фичи в df с помощью 1) нумерации классов 2) one-hot. Возвращает оба варианта\n",
    "\n",
    "def code_and_onehot(df: pd.DataFrame, cols_to_drop: list = []):\n",
    "    ''' \n",
    "    Applies one-hod encoding and classes numeration for categorical features in df.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas Dataframe\n",
    "        Columns are feature values\n",
    "    cols_to_drop: list of strings\n",
    "        Names of columns to drop before encoding\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    (pd.DataFrame, pd.DataFrame)\n",
    "        First one is the df with enumerated categorical features; second one is one-hot-encoded\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    df_codes = deepcopy(df.drop(columns=cols_to_drop))\n",
    "    df_onehot = deepcopy(df.drop(columns=cols_to_drop))\n",
    "\n",
    "    for col in df.drop(columns=cols_to_drop):\n",
    "        if df[col].dtype == object:\n",
    "            df_codes[col] = pd.Categorical(df[col])\n",
    "\n",
    "            df_codes[col] = df_codes[col].cat.codes\n",
    "\n",
    "\n",
    "    df_onehot = pd.get_dummies(df_onehot, drop_first=True)\n",
    "    \n",
    "    return df_codes, df_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс с нейронкой\n",
    "\n",
    "class DenseNN(nn.Module):\n",
    "    def __init__(self, in_features: int, activation=F.relu, do_dropout=False):\n",
    "        super(DenseNN, self).__init__()\n",
    "        self.activation = activation\n",
    "        self.fc1 = nn.Linear(in_features, in_features)\n",
    "        self.fc2 = nn.Linear(in_features, in_features // 3)\n",
    "        self.fc3 = nn.Linear(in_features // 3, 1)\n",
    "        self.do_dropout = do_dropout\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        \n",
    "        if self.do_dropout:\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = self.activation(self.fc2(x))\n",
    "        \n",
    "        if self.do_dropout:\n",
    "            x = self.dropout(x)        \n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как предсказать ZOI_drug_NP\n",
    "## Способ 1 (плохой)\n",
    " - Выполнить ```get_prediction(show_features=True)```. Получится список фич, которые должны быть в данных.\n",
    " - Закодировать значения категориальных фичей (вручную или с помощью Series.replace()). Правила ниже.\n",
    " - Собрать DataFrame из своих данных с правильными колонками и их порядком и скормить его модели с помощью ```get_prediction(df, *args)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Признаки, участвующие в моделях\n",
      "Index(['Bacteria', 'NP_Synthesis', 'Drug', 'Drug_class_drug_bank',\n",
      "       'NP_concentration', 'avg_NP_size', 'shape', 'method', 'ZOI_drug',\n",
      "       'fold_increase_in_antibacterial_activity (%)', 'MDR_check',\n",
      "       'lg_Drug_dose', 'kingdom', 'phylum', 'class', 'order', 'family',\n",
      "       'genus', 'species', 'gram', 'avg_Incub_period', 'growth_temp, C',\n",
      "       'biosafety_level', 'isolated_from', 'pKa', 'NumHAcceptors', 'MolLogP',\n",
      "       'RingCount', 'NumAliphaticRings', 'NumAromaticRings',\n",
      "       'NumAromaticHeterocycles', 'MinPartialCharge', 'MaxPartialCharge',\n",
      "       'BertzCT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('Признаки, участвующие в моделях')\n",
    "get_prediction(show_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Коды категорий (о других категориях модели не знают, другие недоступны)\n",
    "NP_Synthesis\n",
    "{\n",
    "    \"0\": \"chem_synthesis\",\n",
    "    \"1\": \"green_synthesis\"\n",
    "}\n",
    "Bacteria\n",
    "{\n",
    "    \"0\": \"Acinetobacter baumannii\",\n",
    "    \"1\": \"Actinobacillus pleuropneumoniae\",\n",
    "    \"2\": \"Bacillus cereus\",\n",
    "    \"3\": \"Bacillus sp.\",\n",
    "    \"4\": \"Bacillus subtilis\",\n",
    "    \"5\": \"Candida albicans\",\n",
    "    \"6\": \"Candida glabrata\",\n",
    "    \"7\": \"Candida saitoana\",\n",
    "    \"8\": \"Enterobacter cloacae\",\n",
    "    \"9\": \"Enterococcus faecalis\",\n",
    "    \"10\": \"Escherichia coli\",\n",
    "    \"11\": \"Haemophilus influenzae\",\n",
    "    \"12\": \"Klebsiella pneumoniae\",\n",
    "    \"13\": \"Klebsiella sp.\",\n",
    "    \"14\": \"Listeria monocytogenes\",\n",
    "    \"15\": \"Micrococcus luteus\",\n",
    "    \"16\": \"Neisseria mucosa\",\n",
    "    \"17\": \"Pasteurella Multocida\",\n",
    "    \"18\": \"Proteus mirabilis\",\n",
    "    \"19\": \"Proteus sp.\",\n",
    "    \"20\": \"Proteus vulgaris\",\n",
    "    \"21\": \"Pseudomonas aeruginosa\",\n",
    "    \"22\": \"Pseudomonas koreensis\",\n",
    "    \"23\": \"Salmonella enterica\",\n",
    "    \"24\": \"Salmonella typhi\",\n",
    "    \"25\": \"Salmonella typhimurium\",\n",
    "    \"26\": \"Serratia odorifera\",\n",
    "    \"27\": \"Staphylococcus aureus\",\n",
    "    \"28\": \"Staphylococcus epidermidis\",\n",
    "    \"29\": \"Streptococcus uberis\",\n",
    "    \"30\": \"Vibrio cholerae\",\n",
    "    \"31\": \"Vibrio parahaemolyticus\"\n",
    "}\n",
    "phylum\n",
    "{\n",
    "    \"0\": \"Actinomycetota\",\n",
    "    \"1\": \"Ascomycota\",\n",
    "    \"2\": \"Bacillota\",\n",
    "    \"3\": \"Pseudomonadota\"\n",
    "}\n",
    "genus\n",
    "{\n",
    "    \"0\": \"Acinetobacter\",\n",
    "    \"1\": \"Actinobacillus\",\n",
    "    \"2\": \"Bacillus\",\n",
    "    \"3\": \"Candida\",\n",
    "    \"4\": \"Candida glaebosa\",\n",
    "    \"5\": \"Enterobacter\",\n",
    "    \"6\": \"Enterococcus\",\n",
    "    \"7\": \"Escherichia\",\n",
    "    \"8\": \"Haemophilus\",\n",
    "    \"9\": \"Klebsiella\",\n",
    "    \"10\": \"Listeria\",\n",
    "    \"11\": \"Micrococcus\",\n",
    "    \"12\": \"Nakaseomyces\",\n",
    "    \"13\": \"Neisseria\",\n",
    "    \"14\": \"Pasteurella\",\n",
    "    \"15\": \"Proteus\",\n",
    "    \"16\": \"Pseudomonas\",\n",
    "    \"17\": \"Salmonella\",\n",
    "    \"18\": \"Serratia\",\n",
    "    \"19\": \"Staphylococcus\",\n",
    "    \"20\": \"Streptococcus\",\n",
    "    \"21\": \"Vibrio\"\n",
    "}\n",
    "Drug_class_drug_bank\n",
    "{\n",
    "    \"0\": \"Aminoglycosides\",\n",
    "    \"1\": \"Azolidines\",\n",
    "    \"2\": \"Benzene and substituted derivatives\",\n",
    "    \"3\": \"Carboxylic acids and derivatives\",\n",
    "    \"4\": \"Diazanaphthalenes\",\n",
    "    \"5\": \"Fatty Acyls\",\n",
    "    \"6\": \"Lactams\",\n",
    "    \"7\": \"Macrolactams\",\n",
    "    \"8\": \"NC\",\n",
    "    \"9\": \"Organooxygen compounds\",\n",
    "    \"10\": \"Phenol ethers\",\n",
    "    \"11\": \"Quinolines and derivatives\",\n",
    "    \"12\": \"Steroids and steroid derivatives\",\n",
    "    \"13\": \"Tetracyclines\"\n",
    "}\n",
    "order\n",
    "{\n",
    "    \"0\": \"Bacillales\",\n",
    "    \"1\": \"Enterobacterales\",\n",
    "    \"2\": \"Lactobacillales\",\n",
    "    \"3\": \"Micrococcales\",\n",
    "    \"4\": \"Moraxellales\",\n",
    "    \"5\": \"Neisseriales\",\n",
    "    \"6\": \"Pasteurellales\",\n",
    "    \"7\": \"Pseudomonadales\",\n",
    "    \"8\": \"Saccharomycetales\",\n",
    "    \"9\": \"Vibrionales\"\n",
    "}\n",
    "species\n",
    "{\n",
    "    \"0\": \"Acinetobacter calcoaceticus/baumannii complex\",\n",
    "    \"1\": \"Actinobacillus pleuropneumoniae\",\n",
    "    \"2\": \"Bacillus cereus group\",\n",
    "    \"3\": \"Bacillus subtilis group\",\n",
    "    \"4\": \"Candida albicans\",\n",
    "    \"5\": \"Candida glabrata\",\n",
    "    \"6\": \"Candida saitoana\",\n",
    "    \"7\": \"Enterobacter cloacae complex\",\n",
    "    \"8\": \"Enterococcus faecalis\",\n",
    "    \"9\": \"Escherichia coli\",\n",
    "    \"10\": \"Haemophilus influenzae\",\n",
    "    \"11\": \"Klebsiella pneumoniae\",\n",
    "    \"12\": \"Klebsiella sp.\",\n",
    "    \"13\": \"Listeria monocytogenes\",\n",
    "    \"14\": \"Micrococcus luteus\",\n",
    "    \"15\": \"Neisseria mucosa\",\n",
    "    \"16\": \"Pasteurella Multocida\",\n",
    "    \"17\": \"Proteus mirabilis\",\n",
    "    \"18\": \"Proteus sp.\",\n",
    "    \"19\": \"Proteus vulgaris\",\n",
    "    \"20\": \"Pseudomonas aeruginosa group\",\n",
    "    \"21\": \"Pseudomonas fluorescens group\",\n",
    "    \"22\": \"Salmonella enterica\",\n",
    "    \"23\": \"Serratia odorifera\",\n",
    "    \"24\": \"Staphylococcus aureus\",\n",
    "    \"25\": \"Staphylococcus epidermidis\",\n",
    "    \"26\": \"Streptococcus uberis\",\n",
    "    \"27\": \"Vibrio cholerae\",\n",
    "    \"28\": \"Vibrio harveyi group\",\n",
    "    \"29\": \"unclassified Bacillus\"\n",
    "}\n",
    "shape\n",
    "{\n",
    "    \"0\": \"nanorods and triangles\",\n",
    "    \"1\": \"spherical\"\n",
    "}\n",
    "kingdom\n",
    "{\n",
    "    \"0\": \"Bacteria\",\n",
    "    \"1\": \"Fungi\"\n",
    "}\n",
    "isolated_from\n",
    "{\n",
    "    \"0\": \"blood\",\n",
    "    \"1\": \"food\",\n",
    "    \"2\": \"lungs\",\n",
    "    \"3\": \"mammary gland\",\n",
    "    \"4\": \"meat\",\n",
    "    \"5\": \"mouth\",\n",
    "    \"6\": \"nose\",\n",
    "    \"7\": \"respiratory tract\",\n",
    "    \"8\": \"skin\",\n",
    "    \"9\": \"soil\",\n",
    "    \"10\": \"sputum\",\n",
    "    \"11\": \"urine\",\n",
    "    \"12\": \"water\"\n",
    "}\n",
    "family\n",
    "{\n",
    "    \"0\": \"Bacillaceae\",\n",
    "    \"1\": \"Debaryomycetaceae\",\n",
    "    \"2\": \"Enterobacteriaceae\",\n",
    "    \"3\": \"Enterococcaceae\",\n",
    "    \"4\": \"Listeriaceae\",\n",
    "    \"5\": \"Micrococcaceae\",\n",
    "    \"6\": \"Moraxellaceae\",\n",
    "    \"7\": \"Morganellaceae\",\n",
    "    \"8\": \"Neisseriaceae\",\n",
    "    \"9\": \"Pasteurellaceae\",\n",
    "    \"10\": \"Pseudomonadaceae\",\n",
    "    \"11\": \"Saccharomycetaceae\",\n",
    "    \"12\": \"Staphylococcaceae\",\n",
    "    \"13\": \"Streptococcaceae\",\n",
    "    \"14\": \"Vibrionaceae\",\n",
    "    \"15\": \"Yersiniaceae\"\n",
    "}\n",
    "gram\n",
    "{\n",
    "    \"0\": \"n\",\n",
    "    \"1\": \"p\"\n",
    "}\n",
    "class\n",
    "{\n",
    "    \"0\": \"Actinomycetes\",\n",
    "    \"1\": \"Bacilli\",\n",
    "    \"2\": \"Betaproteobacteria\",\n",
    "    \"3\": \"Gammaproteobacteria\",\n",
    "    \"4\": \"Saccharomycetes\"\n",
    "}\n",
    "method\n",
    "{\n",
    "    \"0\": \"MIC\",\n",
    "    \"1\": \"disc_diffusion\",\n",
    "    \"2\": \"well_diffusion\"\n",
    "}\n",
    "Drug\n",
    "{\n",
    "    \"0\": \"amikacin\",\n",
    "    \"1\": \"amoxicillin\",\n",
    "    \"2\": \"amphotericin b\",\n",
    "    \"3\": \"ampicillin\",\n",
    "    \"4\": \"carbenicillin\",\n",
    "    \"5\": \"cefazolin\",\n",
    "    \"6\": \"cefepime\",\n",
    "    \"7\": \"cefixime\",\n",
    "    \"8\": \"cefotaxime\",\n",
    "    \"9\": \"ceftazidime\",\n",
    "    \"10\": \"ceftriaxone\",\n",
    "    \"11\": \"cephalexin\",\n",
    "    \"12\": \"chloramphenicol\",\n",
    "    \"13\": \"ciprofloxacin\",\n",
    "    \"14\": \"clindamycin\",\n",
    "    \"15\": \"co-trimoxazole\",\n",
    "    \"16\": \"colistin\",\n",
    "    \"17\": \"doxycycline\",\n",
    "    \"18\": \"erythromycin\",\n",
    "    \"19\": \"faropenem\",\n",
    "    \"20\": \"fusidic acid\",\n",
    "    \"21\": \"gentamicin\",\n",
    "    \"22\": \"imipenem\",\n",
    "    \"23\": \"kanamycin\",\n",
    "    \"24\": \"levofloxacin\",\n",
    "    \"25\": \"mupirocin\",\n",
    "    \"26\": \"nalidixic acid\",\n",
    "    \"27\": \"neomycin\",\n",
    "    \"28\": \"nitrofurantoin\",\n",
    "    \"29\": \"penicillin\",\n",
    "    \"30\": \"piperacillin\",\n",
    "    \"31\": \"polymyxin\",\n",
    "    \"32\": \"rifampicin\",\n",
    "    \"33\": \"streptomycin\",\n",
    "    \"34\": \"tetracycline\",\n",
    "    \"35\": \"trimethoprim\",\n",
    "    \"36\": \"vancomycin\"\n",
    "}\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Способ 2 (хороший)\n",
    " - Добавить строку со своим экспериментом в ```dataframe``` с почищенными данными в последнюю строку\n",
    " - Применить кодирование\n",
    " - Сделать предсказание\n",
    " - Взять последнее предсказанное значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv('clean_data.csv', index_col=0)\n",
    "\n",
    "# Добавьте в clean_df свои эксперименты\n",
    "\n",
    "clean_df_code, clean_df_onehot = code_and_onehot(clean_df)\n",
    "\n",
    "pred = get_prediction(clean_df_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 547 entries, 0 to 546\n",
      "Columns: 205 entries, NP_concentration to isolated_from_water\n",
      "dtypes: float64(17), int64(9), uint8(179)\n",
      "memory usage: 211.0 KB\n"
     ]
    }
   ],
   "source": [
    "clean_df_onehot.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Способ 3 (нейронновый)\n",
    " - Сделать то же, что в способе 2\n",
    " - Призвать с помощью команд ниже нейронку и сделать предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 242 features, but MinMaxScaler is expecting 203 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      5\u001b[0m scaler \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mscaler.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m scaler\u001b[39m.\u001b[39;49mtransform(clean_df_onehot)\n\u001b[1;32m      7\u001b[0m pred \u001b[39m=\u001b[39m model(clean_df_onehot\u001b[39m.\u001b[39mdrop())\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:514\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Scale features of X according to feature_range.\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \n\u001b[1;32m    502\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39m    Transformed data.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    512\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 514\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    515\u001b[0m     X,\n\u001b[1;32m    516\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy,\n\u001b[1;32m    517\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    518\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    519\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    520\u001b[0m )\n\u001b[1;32m    522\u001b[0m X \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_\n\u001b[1;32m    523\u001b[0m X \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/sklearn/base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 625\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    627\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/sklearn/base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    415\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 242 features, but MinMaxScaler is expecting 203 features as input."
     ]
    }
   ],
   "source": [
    "n_features = clean_df_onehot.shape[1]-1\n",
    "model = torch.load('best_nn.pkl')\n",
    "model.eval()\n",
    "\n",
    "scaler = pickle.load(open('scaler.pkl', 'rb'))\n",
    "scaler.transform(clean_df_onehot)\n",
    "pred = model(clean_df_onehot.drop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3b836c7ef044d43059c7846a59355f0b4cbb71a588c1f9492eaa9138c6b55f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
